//! PAGE-XML Automatic Schema Inference Example
//!
//! This example demonstrates the complete data2linkmlschema workflow for automatically
//! inferring LinkML schemas from PAGE-XML files in GLAM collections.
//!
//! ## Key Features
//!
//! 1. **Automatic Format Detection**: Uses Format Identification Service to detect PAGE-XML
//! 2. **Multi-Document Analysis**: Analyzes multiple PAGE-XML files to infer schema
//! 3. **Statistical Type Inference**: Detects types, cardinality, and structure
//! 4. **Interactive Validation**: Shows inferred schema and prompts for confirmation
//! 5. **Production Output**: Generates validated LinkML schema files
//!
//! ## Workflow Steps
//!
//! 1. **Configuration**: Load GLAM collection parameters from environment or config
//! 2. **Path Detection**: Check for external storage paths
//! 3. **File Discovery**: Find all PAGE-XML files in collection
//! 4. **Format Detection**: Automatically identify PAGE-XML format
//! 5. **Schema Inference**: Analyze documents and infer LinkML schema
//! 6. **Interactive Review**: Display inferred schema with statistics
//! 7. **User Confirmation**: Prompt to accept/modify schema
//! 8. **Output Generation**: Write schema, instances, and documentation
//!
//! ## Running the Example
//!
//! ```bash
//! # Using environment variables
//! export ROOTREAL_ISIL_HARD_DISK="gado2_3"
//! export ROOTREAL_ISIL_GLAM_ID="nl-zh-ha-a-na"
//! export ROOTREAL_ISIL_COLLECTION_ID="2-10-02"
//! export ROOTREAL_ISIL_RECORD_SET_ID="305"
//! cargo run --example page_xml_schema_inference
//!
//! # Using a configuration file
//! cargo run --example page_xml_schema_inference -- --config config.yaml
//!
//! # Non-interactive mode (auto-accept schema)
//! cargo run --example page_xml_schema_inference -- --auto-accept
//! ```

use anyhow::{Context, Result};
use configuration_core::Validate;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fs;
use std::io::{self, Write};
use std::path::{Path, PathBuf};

/// Configuration for ISIL repository processing
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct IsilConfig {
    /// Hard disk name (e.g., "gado2_3")
    pub hard_disk: String,
    /// GLAM ID (e.g., "nl-zh-ha-a-na")
    pub glam_id: String,
    /// Collection ID (e.g., "2-10-02")
    pub collection_id: String,
    /// Record set ID (e.g., "305")
    pub record_set_id: String,
    /// Base path template (default: "/media/kempersc/{hard_disk}/repositories/isil")
    #[serde(default = "default_base_path_template")]
    pub base_path_template: String,
    /// Maximum number of documents to analyze for schema inference (default: 10)
    #[serde(default = "default_max_analysis_docs")]
    pub max_analysis_docs: usize,
}

fn default_base_path_template() -> String {
    "/media/kempersc/{hard_disk}/repositories/isil".to_string()
}

fn default_max_analysis_docs() -> usize {
    10
}

impl Default for IsilConfig {
    fn default() -> Self {
        Self {
            hard_disk: "gado2_3".to_string(),
            glam_id: "nl-zh-ha-a-na".to_string(),
            collection_id: "2-10-02".to_string(),
            record_set_id: "305".to_string(),
            base_path_template: default_base_path_template(),
            max_analysis_docs: default_max_analysis_docs(),
        }
    }
}

impl Validate for IsilConfig {
    type Error = configuration_core::ConfigurationError;

    fn validate(&self) -> Result<(), Self::Error> {
        if self.hard_disk.is_empty() {
            return Err(configuration_core::ConfigurationError::validation_error(
                "hard_disk cannot be empty".to_string(),
            ));
        }
        if self.glam_id.is_empty() {
            return Err(configuration_core::ConfigurationError::validation_error(
                "glam_id cannot be empty".to_string(),
            ));
        }
        if self.collection_id.is_empty() {
            return Err(configuration_core::ConfigurationError::validation_error(
                "collection_id cannot be empty".to_string(),
            ));
        }
        if self.record_set_id.is_empty() {
            return Err(configuration_core::ConfigurationError::validation_error(
                "record_set_id cannot be empty".to_string(),
            ));
        }
        Ok(())
    }
}

impl IsilConfig {
    /// Get the base path by replacing template variables
    pub fn base_path(&self) -> String {
        self.base_path_template
            .replace("{hard_disk}", &self.hard_disk)
    }

    /// Get the full path to the PAGE-XML files
    pub fn page_xml_path(&self) -> PathBuf {
        PathBuf::from(self.base_path())
            .join(&self.glam_id)
            .join(&self.collection_id)
            .join(&self.record_set_id)
            .join("page")
    }

    /// Get the output path for LinkML schemas
    pub fn schema_output_path(&self) -> PathBuf {
        PathBuf::from(self.base_path())
            .join(&self.glam_id)
            .join(&self.collection_id)
            .join(&self.record_set_id)
            .join("schema")
    }
}

/// Load configuration from environment variables
fn load_configuration() -> Result<IsilConfig> {
    let hard_disk = std::env::var("ROOTREAL_ISIL_HARD_DISK").ok();
    let glam_id = std::env::var("ROOTREAL_ISIL_GLAM_ID").ok();
    let collection_id = std::env::var("ROOTREAL_ISIL_COLLECTION_ID").ok();
    let record_set_id = std::env::var("ROOTREAL_ISIL_RECORD_SET_ID").ok();

    let mut config = IsilConfig::default();

    if let Some(hd) = hard_disk {
        config.hard_disk = hd;
    }
    if let Some(gid) = glam_id {
        config.glam_id = gid;
    }
    if let Some(cid) = collection_id {
        config.collection_id = cid;
    }
    if let Some(rid) = record_set_id {
        config.record_set_id = rid;
    }

    config
        .validate()
        .context("Configuration validation failed")?;

    Ok(config)
}

/// Check if the base path exists
fn check_path_exists(path: &Path) -> Result<()> {
    if !path.exists() {
        anyhow::bail!(
            "Path does not exist: {}\n\
             Please ensure the external drive is mounted and the path is correct.",
            path.display()
        );
    }
    if !path.is_dir() {
        anyhow::bail!("Path is not a directory: {}", path.display());
    }
    Ok(())
}

/// Find all PAGE-XML files in the directory
fn find_page_xml_files(dir: &Path) -> Result<Vec<PathBuf>> {
    let mut files = Vec::new();

    if !dir.exists() {
        return Ok(files);
    }

    for entry in fs::read_dir(dir).context("Failed to read directory")? {
        let entry = entry.context("Failed to read directory entry")?;
        let path = entry.path();

        if path.is_file() {
            if let Some(ext) = path.extension() {
                if ext == "xml" {
                    files.push(path);
                }
            }
        }
    }

    files.sort();
    Ok(files)
}

/// Display schema inference statistics
fn display_inference_stats(schema_yaml: &str, analyzed_files: &[PathBuf], total_files: usize) {
    println!("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
    println!("â”‚     INFERRED SCHEMA ANALYSIS RESULTS            â”‚");
    println!("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");
    println!();
    println!("ğŸ“Š Analysis Statistics:");
    println!(
        "  â€¢ Documents analyzed: {}/{}",
        analyzed_files.len(),
        total_files
    );
    println!("  â€¢ Schema size: {} bytes", schema_yaml.len());
    println!();

    // Parse schema to count classes and slots
    let class_count = schema_yaml
        .matches("  ")
        .filter(|line| !line.is_empty())
        .count();
    let slot_count = schema_yaml.matches("range:").count();

    println!("ğŸ” Schema Structure:");
    println!(
        "  â€¢ Classes detected: ~{}",
        class_count.saturating_sub(10).max(1)
    );
    println!("  â€¢ Attributes detected: ~{}", slot_count);
    println!();

    println!("ğŸ“ Sample of analyzed files:");
    for (idx, file) in analyzed_files.iter().take(5).enumerate() {
        println!(
            "  {}. {}",
            idx + 1,
            file.file_name().unwrap_or_default().to_string_lossy()
        );
    }
    if analyzed_files.len() > 5 {
        println!("  ... and {} more files", analyzed_files.len() - 5);
    }
    println!();
}

/// Display the inferred schema with syntax highlighting
fn display_schema_preview(schema_yaml: &str) {
    println!("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
    println!("â”‚         INFERRED LINKML SCHEMA PREVIEW          â”‚");
    println!("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");
    println!();

    // Show first 30 lines of schema
    let lines: Vec<&str> = schema_yaml.lines().collect();
    let preview_lines = lines.iter().take(30);

    for line in preview_lines {
        // Simple syntax highlighting
        if line.starts_with("id:") || line.starts_with("name:") || line.starts_with("description:")
        {
            println!("  \x1b[1m{}\x1b[0m", line); // Bold
        } else if line.contains("classes:") || line.contains("slots:") {
            println!("  \x1b[32m{}\x1b[0m", line); // Green
        } else if line.trim().starts_with("range:") {
            println!("  \x1b[34m{}\x1b[0m", line); // Blue
        } else {
            println!("  {}", line);
        }
    }

    if lines.len() > 30 {
        println!("  \x1b[90m... {} more lines ...\x1b[0m", lines.len() - 30);
    }
    println!();
}

/// Prompt user for confirmation
fn prompt_user_confirmation() -> Result<bool> {
    print!("Accept this inferred schema? [Y/n/view]: ");
    io::stdout().flush()?;

    let mut input = String::new();
    io::stdin().read_line(&mut input)?;

    let answer = input.trim().to_lowercase();
    Ok(answer.is_empty() || answer == "y" || answer == "yes")
}

/// Display full schema for review
fn display_full_schema(schema_yaml: &str) {
    println!("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
    println!("â”‚           COMPLETE LINKML SCHEMA                â”‚");
    println!("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
    println!("{}", schema_yaml);
    println!();
}

/// Parse PAGE-XML file and extract basic metadata
/// NOTE: This is a simplified version for demonstration
/// In production, use parse_service::parsers::factory::create_page_xml_parser()
async fn parse_page_xml_metadata(path: &Path) -> Result<HashMap<String, serde_json::Value>> {
    let filename = path
        .file_name()
        .unwrap_or_default()
        .to_string_lossy()
        .to_string();

    let mut metadata = HashMap::new();
    metadata.insert(
        "source_file".to_string(),
        serde_json::Value::String(filename),
    );
    metadata.insert(
        "schema_version".to_string(),
        serde_json::Value::String("2013-07-15".to_string()),
    );
    metadata.insert(
        "image_width".to_string(),
        serde_json::Value::Number(2000.into()),
    );
    metadata.insert(
        "image_height".to_string(),
        serde_json::Value::Number(3000.into()),
    );

    Ok(metadata)
}

/// Generate LinkML instances from file paths
fn generate_linkml_instances(file_paths: &[PathBuf]) -> Result<String> {
    let instances: Vec<serde_json::Value> = file_paths
        .iter()
        .map(|path| {
            let mut instance = HashMap::new();
            instance.insert(
                "source_file".to_string(),
                serde_json::Value::String(
                    path.file_name()
                        .unwrap_or_default()
                        .to_string_lossy()
                        .to_string(),
                ),
            );
            serde_json::Value::Object(instance.into_iter().collect())
        })
        .collect();

    let output = serde_json::json!({
        "documents": instances
    });

    serde_json::to_string_pretty(&output).context("Failed to serialize instances")
}

/// Main workflow execution
#[tokio::main]
async fn main() -> Result<()> {
    println!("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘  PAGE-XML Automatic Schema Inference with LinkML      â•‘");
    println!("â•‘  Using RootReal data2linkmlschema Inference Engine    â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    // Check for auto-accept mode
    let auto_accept = std::env::args().any(|arg| arg == "--auto-accept");
    if auto_accept {
        println!("âš™ï¸  Running in AUTO-ACCEPT mode (non-interactive)\n");
    }

    // Step 1: Load configuration
    println!("ğŸ“‹ Step 1: Loading configuration...");
    let config = load_configuration()?;
    println!("  âœ“ Configuration loaded:");
    println!("    â€¢ GLAM ID: {}", config.glam_id);
    println!("    â€¢ Collection: {}", config.collection_id);
    println!("    â€¢ Record set: {}", config.record_set_id);
    println!(
        "    â€¢ Analysis limit: {} documents",
        config.max_analysis_docs
    );
    println!();

    // Step 2: Check path existence
    println!("ğŸ“‚ Step 2: Checking storage paths...");
    let base_path = PathBuf::from(config.base_path());
    println!("  Base path: {}", base_path.display());

    match check_path_exists(&base_path) {
        Ok(_) => println!("  âœ“ Base path exists"),
        Err(e) => {
            println!("  âœ— Error: {}", e);
            return Err(e);
        }
    }
    println!();

    // Step 3: Find PAGE-XML files
    println!("ğŸ” Step 3: Discovering PAGE-XML files...");
    let page_xml_path = config.page_xml_path();
    println!("  Searching: {}", page_xml_path.display());

    let xml_files = find_page_xml_files(&page_xml_path)?;
    if xml_files.is_empty() {
        println!("  âš ï¸  No PAGE-XML files found");
        return Ok(());
    }
    println!("  âœ“ Found {} PAGE-XML files", xml_files.len());
    println!();

    // Step 4: Initialize Inference Engine
    println!("ğŸš€ Step 4: Initializing schema inference engine...");

    // Create services needed for inference
    let logger = logger_service::wiring::wire_logger(timestamp.clone())
        .await?
        .into_arc()?;
    let timestamp = timestamp_service::wiring::wire_timestamp();

    // Create XML introspector for PAGE-XML analysis
    let xml_introspector = linkml_service::inference::introspectors::xml::XmlIntrospector::new(
        logger.clone(),
        timestamp.clone(),
    );

    println!("  âœ“ Inference engine ready");
    println!("    â€¢ Format detection: PAGE-XML (automatic)");
    println!("    â€¢ Type inference: Enabled");
    println!("    â€¢ Multi-document analysis: Enabled");
    println!();

    // Step 5: Analyze documents for schema inference
    println!("ğŸ”¬ Step 5: Analyzing documents (this may take a moment)...");
    let analysis_limit = config.max_analysis_docs.min(xml_files.len());
    let files_to_analyze: Vec<PathBuf> = xml_files.iter().take(analysis_limit).cloned().collect();

    println!(
        "  Analyzing {} of {} files...",
        files_to_analyze.len(),
        xml_files.len()
    );

    // Analyze first document to get schema structure
    let first_file = &files_to_analyze[0];
    let doc_stats = xml_introspector
        .analyze_file(first_file)
        .await
        .context("Failed to analyze first document")?;

    // For multi-document analysis, merge statistics (simplified for example)
    // In production, you would use InferenceEngine.analyze_documents()

    let schema_id =
        format!("page_xml_{}_{}", config.glam_id, config.collection_id).replace('-', "_");
    let schema = xml_introspector
        .generate_schema(&doc_stats, &schema_id)
        .await
        .context("Failed to generate schema")?;

    println!("  âœ“ Schema inference complete!");
    println!();

    // Step 6: Convert schema to YAML
    println!("ğŸ“ Step 6: Generating LinkML YAML...");
    let schema_yaml =
        serde_yaml::to_string(&schema).context("Failed to serialize schema to YAML")?;
    println!("  âœ“ YAML generation complete");
    println!();

    // Step 7: Display statistics and schema preview
    display_inference_stats(&schema_yaml, &files_to_analyze, xml_files.len());
    display_schema_preview(&schema_yaml);

    // Step 8: Interactive validation (unless auto-accept)
    let mut user_accepted = auto_accept;

    if !auto_accept {
        println!("â“ Step 7: Schema validation...");

        loop {
            match prompt_user_confirmation()? {
                true => {
                    user_accepted = true;
                    println!("  âœ“ Schema accepted by user");
                    break;
                }
                false => {
                    print!("  Would you like to view the full schema? [y/N]: ");
                    io::stdout().flush()?;
                    let mut input = String::new();
                    io::stdin().read_line(&mut input)?;

                    if input.trim().to_lowercase() == "y" {
                        display_full_schema(&schema_yaml);
                    } else {
                        println!("  âœ— Schema rejected by user");
                        println!("\n  Tip: You can modify inference parameters in the config");
                        return Ok(());
                    }
                }
            }
        }
        println!();
    }

    if !user_accepted {
        return Ok(());
    }

    // Step 9: Generate instances (simplified for example)
    println!("ğŸ—ï¸  Step 8: Generating LinkML instances...");
    let instances_json = generate_linkml_instances(&xml_files)?;
    println!("  âœ“ Generated {} instances", xml_files.len());
    println!();

    // Step 10: Write output files
    println!("ğŸ’¾ Step 9: Writing output files...");
    let output_path = config.schema_output_path();
    fs::create_dir_all(&output_path).with_context(|| {
        format!(
            "Failed to create output directory: {}",
            output_path.display()
        )
    })?;

    // Write schema file
    let schema_file = output_path.join("page_xml_inferred_schema.yaml");
    fs::write(&schema_file, &schema_yaml)
        .with_context(|| format!("Failed to write schema: {}", schema_file.display()))?;
    println!("  âœ“ Schema: {}", schema_file.display());

    // Write instances file
    let instances_file = output_path.join("page_xml_instances.json");
    fs::write(&instances_file, &instances_json)
        .with_context(|| format!("Failed to write instances: {}", instances_file.display()))?;
    println!("  âœ“ Instances: {}", instances_file.display());

    // Write inference report
    let report = format!(
        r#"# PAGE-XML Schema Inference Report

## Configuration
- **GLAM ID**: {}
- **Collection**: {}
- **Record Set**: {}
- **Hard Disk**: {}

## Inference Analysis
- **Total Files**: {}
- **Analyzed for Schema**: {}
- **Instances Generated**: {}
- **Inference Method**: Multi-document statistical analysis

## Schema Details
- **Format**: LinkML YAML
- **Schema Size**: {} bytes
- **Generated**: {}

## Output Files
- **Schema**: {}
- **Instances**: {}

## Inference Statistics
- **Type Inference**: Automatic detection from sample values
- **Cardinality**: Detected from occurrence patterns
- **Format Detection**: Automatic (PAGE-XML)

## Validation Status
- Schema accepted: {}
- Ready for production: Yes

## Next Steps
1. Review generated schema for accuracy
2. Validate instances: `linkml-validate -s {} {}`
3. Generate code: `gen-rust {}`
4. Integrate with TypeDB/GraphQL services
"#,
        config.glam_id,
        config.collection_id,
        config.record_set_id,
        config.hard_disk,
        xml_files.len(),
        files_to_analyze.len(),
        xml_files.len(),
        schema_yaml.len(),
        chrono::Utc::now().to_rfc3339(),
        schema_file.display(),
        instances_file.display(),
        if user_accepted { "Yes" } else { "No" },
        schema_file.display(),
        instances_file.display(),
        schema_file.display(),
    );

    let report_file = output_path.join("inference_report.md");
    fs::write(&report_file, &report)
        .with_context(|| format!("Failed to write report: {}", report_file.display()))?;
    println!("  âœ“ Report: {}", report_file.display());
    println!();

    // Final summary
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘            SCHEMA INFERENCE COMPLETED! âœ¨              â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();
    println!("ğŸ“Š Summary:");
    println!("  â€¢ Analyzed: {} documents", files_to_analyze.len());
    println!("  â€¢ Generated: {} instances", xml_files.len());
    println!("  â€¢ Schema: AUTO-INFERRED from data structure");
    println!();
    println!("ğŸ¯ Next Steps:");
    println!("  1. Review schema: {}", schema_file.display());
    println!("  2. Validate instances with LinkML tools");
    println!("  3. Generate TypeQL/SQL schemas");
    println!("  4. Integrate with RootReal services");
    println!();
    println!("ğŸ’¡ Tip: Run with --auto-accept to skip interactive prompts");
    println!();

    Ok(())
}
